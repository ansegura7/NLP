From Regularization Operators to Support Vector Kernels We derive the correspondence between regularization operators used in Regularization Networks and Hilbert Schmidt Kernels appearing in Support Vector Machines. More specifically, we prove that the Green's Functions associated with regularization operators are suitable Support Vector Kernels with equivalent regularization properties. As a by--product we show that a large number of Radial Basis Functions namely conditionally positive definite functions may be used as Support Vector kernels. 1 INTRODUCTION  Support Vector (SV) Machines for pattern recognition, regression estimation and operator inversion exploit the idea of transforming into a high dimensional feature space where they perform a linear algorithm. Instead of evaluating this map explicitly, one uses Hilbert Schmidt Kernels k(x; y) which correspond to dot products of the mapped data in high dimensional space, i.e.  k(x; y) = (\Phi(x) \Delta \Phi(y)) (1) with \Phi : R  n  ! F denoting the map into feature space. Mostly, this m...
