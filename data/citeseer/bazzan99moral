Moral Sentiments in Multi-Agent Systems We present a simulation of a society of agents where some  of them have "moral sentiments" towards the agents that belong to the  same social group, using the Iterated Prisoner's Dilemma as a metaphor  for the social interactions. Besides the well-understood phenomenon of  short-sighted, self-interested agents performing well in the short-term  but ruining their chances of such performance in the long run in a world  of reciprocators, the results suggest that, where some agents are more  generous than that, these agents have a positive impact on the social  group to which they belong, without compromising too much their individual  performance (i.e., the group performance improves). The inspiration  for this project comes from a discussion on Moral Sentiments by  M.Ridley. We describe various simulations where conditions and parameters  over determined dimensions were arranged to account for different  types and compositions of societies. Further, we indicate several lessons  that arise from the analysis of the results and comparison of the different  experiments. We also relate this work to our previous anthropological  approach to the adaptation of migrant agents, and argue that allowing  agents to possess suitably-chosen emotions can have a decisive impact on  Multi-Agent Systems. This implies that some common notions of agent  autonomy (and related concepts) should be reexamined.
