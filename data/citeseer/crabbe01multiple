Multiple Goal Q-Learning: Issues and Functions This paper addresses the concerns of agents using reinforcement learning to learn to achieve multiple simultaneous goals. It proves that an algorithm based on acting upon the maximal goal at any one time will, in many cases, not not produce the Maximal Expected Utility for the agent. The paper then examines the type of function approximator necessary for the agent's reinforcement learning system, and concludes that a bi-linear function is the best compromise between expressive power and speed of learning.
