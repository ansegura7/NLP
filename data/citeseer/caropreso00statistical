Statistical Phrases in Automated Text Categorization In this work we investigate the usefulness of n-grams for document indexing in text categorization  (TC). We call n-gram a set t k of n word stems, and we say that t k occurs in a document  d j when a sequence of words appears in d j that, after stop word removal and stemming,  consists exactly of the n stems in t k , in some order. Previous researches have investigated the  use of n-grams (or some variant of them) in the context of specific learning algorithms, and  thus have not obtained general answers on their usefulness for TC. In this work we investigate  the usefulness of n-grams in TC independently of any specific learning algorithm. We do so  by applying feature selection to the pool of all #-grams (#  #  n), and checking how many  n-grams score high enough to be selected in the top # #-grams. We report the results of  our experiments, using several feature selection functions and varying values of #, performed  on the Reuters-21578 standard TC benchmark. We also report results of making actual use  of the selected n-grams in the context of a linear classifier induced by means of the Rocchio  method.
