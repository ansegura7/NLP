Integrating Multiple Classifiers In Visual Object Detectors Learned From User Input There have been many recent efforts in contentbased retrieval to perform automatic classification of images/visual objects. Most approaches, however, have focused on using individual classifiers. In this paper, we study the way in which, in a dynamic framework, multiple classifiers can be combined when applying Visual Object Detectors. We propose a hybrid classifier combination approach, in which decisions of individual classifiers are combined in the following three ways: (1) classifier fusion, (2) classifier cooperation, and (3) hierarchical combination. In earlier work, we presented the Visual Apprentice framework, in which a user defines visual object models via a multiple-level object-definition hierarchy (region, perceptual-area, object part, and object). As the user provides examples from images or videos, visual features are extracted and multiple classifiers are learned for each node of the hierarchy. In this paper, we discuss the benefits of hybrid classifier combination in the Visual Apprentice framework, and show some experimental results in classifier fusion. These results suggest possible improvements in classification accuracy, particularly of detectors reported earlier for Baseball video, images with skies, and images with handshakes.
