Evaluating Interactive Cross-Language Information Retrieval: Document selection . The problem of finding documents that are written in a language  that the searcher cannot read is perhaps the most challenging  application of Cross-Language Information Retrieval (CLIR) technology.  The first Cross-Language Evaluation Forum (CLEF) provided an  excellent venue for assessing the performance of automated CLIR techniques,  but little is known about how searchers and systems might interact  to achieve better cross-language search results than automated  systems alone can provide. This paper explores the question of how interactive  approaches to CLIR might be evaluated, suggesting an initial  focus on evaluation of interactive document selection. Important evaluation  issues are identified, the structure of an interactive CLEF evaluation  is proposed, and the key research communities that could be brought together  by such an evaluation are introduced.  1 Introduction  Cross-language information retrieval (CLIR) has somewhat uncharitably been referred to as "the problem ...
