A Gesture Interface for Human-Robot-Interaction We present a person-independent gesture interface implemented on a real robot which allows the user to give simple commands ,e.g., how to grasp an object and where to put it. The gesture analysis relies on realtime tracking of the user's hand and a re\Thetaned analysis of the hand's shape in the presence of varying complex backgrounds. 1. Introduction  Robots of the future will interact with humans in a natural way. They will understand spoken and gestural commands and will articulate themselves by speech and gesture. We are especially interested in gestural interfaces for robots operating in uncontrolled real world environments. This imposes several constraints on human-robot-interaction as a special case of human-computer-interaction:  1. The robot visual system must cope with variable and possibly complex backgrounds. A system requiring uniform background is not exible enough for real world applications. 2. The system must be person independent. Many users should be able to operate ...
