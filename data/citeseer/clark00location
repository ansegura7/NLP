Location and Recovery of Text on Oriented Surfaces We present a method for extracting text from images where the text plane is not necessarily fronto-parallel to the camera. Initially, we locate local image features such as borders and page edges. We then use perceptual grouping on these features to find rectangular regions in the scene. These regions are hypothesised to be pages or planes that may contain text. Edge distributions are then used for the assessment of these potential regions, providing a measure of confidence. It will be shown that the text may then be transformed to a fronto-parallel view suitable, for example, for an OCR system or other higher level recognition. The proposed method is scale independent (of the size of the text). We illustrate the algorithm using various examples.  Keywords: Oriented Text, Perspective Recovery of Text, Edge Angle Distribution  1. INTRODUCTION  Location and recovery of text in a scene would be useful in the context of wearable computing, desk computing, or unguided robotic motion. Such a...
