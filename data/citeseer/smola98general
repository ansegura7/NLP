General Cost Functions for Support Vector Regression The concept of Support Vector Regression is extended to a more general class of convex cost functions. Moreover it is shown how the resulting convex constrained optimization problems can be efficiently solved by a Primal--Dual Interior Point path following method. Both computational feasibility and improvement of estimation is demonstrated in the experiments. 1. Introduction  1.1. Risk Minimization  In the following we will consider the problem of regression estimation: For some probability density function p(x; y) on R  n\Omega  R and some cost function  C(??) find a function f that minimizes the following risk functional.  R[f ] =  Z  C(y \Gamma f(x))p(x; y)dxdy (1) However we do not know p(x; y). Instead we only have observations f(x 1 ; y 1 ); : : : (x ` ; y ` )g; x i 2  R  n  ; y i 2 R at hand that have been drawn iid (independent identially distributed) from p(x; y). Hence the first guess would be to replace p by the empirical density derived from our observations and minimize the...
