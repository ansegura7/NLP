Computers Seeing People this paper, we present methods that give machines the ability to see people, interpret their actions and interact with them. We present the motivating factors behind this work, examples of how such computational methods are developed and their applications. The basic reason for providing machines the ability to see people really depends on the task we are associating with a machine. An industrial vision system aimed at extracting defects on an assembly line need not know anything about people. Similarly, a computer used for email and text writing need not see and perceive the users gestures and expressions. However, if our interest is to build intelligent machines that can work with us, support our needs and be our helpers, than it maybe required for these machines to know more about who they are supporting and helping. If our computers are to do more then support our text-based needs like writing papers, spreadsheets, and communicating via email; perhaps take on a role of being a personal assistant, then the ability to see a person is essential. Such an ability to perceive people is something that we take for granted in our everyday interactions with each other. At present our model of a machine or more specifically of a computer is something that is placed in the corner of the room. It is deaf, dumb, and blind, having no sense of the environment that it is in or of the person that is near it. We communicate with this computer using a coded sequence of tappings on a keyboard. Imagine a computer that knows that you are near it, that you are looking at it, knows who you are and what you are trying to do. Imagine a machine that can interpret a video signal based on who is in the scene and what they are doing. Such abilities in a computer are hard to imagine, unless it has...
