Scaling Question Answering to the Web The wealth of information on the web makes it an attractive resource for seeking quick answers to simple, factual questions such as ???who was the first American in space? ??? or ???what is the second tallest mountain in the world? ??? Yet today???s most advanced web search services (e.g., Google and AskJeeves) make it surprisingly tedious to locate answers to such questions. In this paper, we extend question-answering techniques, first studied in the information retrieval literature, to the web and experimentally evaluate their performance. First we introduce MULDER, which we believe to be the first general-purpose, fully-automated question-answering system available on the web. Second, we describe MULDER???s architecture, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall. Finally, we compare MULDER???s performance to that of Google and AskJeeves on questions drawn from the TREC-8 question answering track. We find that MULDER???s recall is more than a factor of three higher than that of AskJeeves. In addition, we find that Google requires 6.6 times as much user effort to achieve the same level of recall as MULDER.
