{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Spell Checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Created by Andrés Segura Tinoco**\n",
    "- **Created on June 14, 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Spell checker** (or spell corrector) is an application, program or a feature of a program that checks for misspellings in a text and offers possible solutions (candidate words). <a href=\"#link_one\">[1]</a>\n",
    "\n",
    "A basic spell checker carries out the following processes:\n",
    "- It scans the text and extracts the words contained in it.\n",
    "- It then compares each word with a known list of correctly spelled words (i.e. a dictionary).\n",
    "- An additional step is a language-dependent algorithm for handling morphology.\n",
    "- The program's user interface will allow users to approve or reject replacements and modify the program's operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spell Checker from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python libraries\n",
    "import io\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary/vocabulary from a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function to read a plain text file\n",
    "def read_text_file(file_path):\n",
    "    text = \"\"\n",
    "    with io.open(file_path, 'r', encoding = 'ISO-8859-1') as f:\n",
    "        text = f.read()\n",
    "    return text;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an array with the clean words of the document\n",
    "def get_doc_words(plain_text):\n",
    "    doc_words = []\n",
    "    \n",
    "    # Cleaing the text\n",
    "    clean_text = re.sub('[^a-zA-Z]', ' ', plain_text.lower())\n",
    "    \n",
    "    # Tokenize sentences in words\n",
    "    doc_words = clean_text.split()\n",
    "    \n",
    "    return doc_words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235134"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get text sample\n",
    "file_path = \"../data/en/Moby Dick or the Whale - Herman Melville.txt\"\n",
    "plain_text = read_text_file(file_path)\n",
    "len(plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219153"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create document word list\n",
    "doc_words = get_doc_words(plain_text)\n",
    "len(doc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or', 'the', 'whale', 'by', 'herman', 'melville', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'title', 'moby', 'dick', 'or', 'the', 'whale', 'author', 'herman', 'melville', 'release', 'date', 'december', 'ebook', 'last', 'updated', 'december', 'language', 'english', 'character', 'set', 'encoding', 'utf', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'moby', 'dick', 'or', 'the', 'whale', 'produced', 'by', 'daniel', 'lazarus', 'jonesey', 'and', 'david']\n"
     ]
    }
   ],
   "source": [
    "# Show 100 first words of the vocabulary\n",
    "print(doc_words[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create term frequency list of the document words\n",
    "term_freq = Counter(doc_words)\n",
    "term_freq['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spell Checker model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Peter Norvig’s 21-line spelling corrector using probability theory. <a href=\"#link_two\" >[2]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Spell Checker class\n",
    "class SpellChecker:\n",
    "    \n",
    "    def __init__(self, term_freq):\n",
    "        \"Constructor.\"\n",
    "        self.w_rank = {}\n",
    "        self.letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        \n",
    "        N = sum(term_freq.values())\n",
    "        for term in term_freq:\n",
    "            self.w_rank[term] = term_freq[term] / N\n",
    "    \n",
    "    def P(self, word): \n",
    "        \"Probability of 'word'.\"\n",
    "        return self.w_rank.get(word, 0)\n",
    "\n",
    "    def known(self, words): \n",
    "        \"The subset of 'words' that appear in the dictionary of w_rank.\"\n",
    "        return set(w for w in words if w in self.w_rank)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from 'word'.\"\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in self.letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in self.letters]\n",
    "        \n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word): \n",
    "        \"All edits that are two edits away from 'word'.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n",
    "    \n",
    "    def correction(self, word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key = self.P)\n",
    "    \n",
    "    def candidates(self, word): \n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spell Checker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "sp_model = SpellChecker(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06635546855393264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get probability of the word 'the'\n",
    "sp_model.P('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get probability of the word 'unmentioned'\n",
    "sp_model.P('unmentioned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get words that exist in the dictionary\n",
    "sp_model.known(['the', 'unmentioned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'castle'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the correction for word 'castli'\n",
    "sp_model.correction('castli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'walk', 'weak'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get candidates for word 'wlak'\n",
    "sp_model.candidates('wlak')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spell Checker using PySpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure Python Spell Checking based on Peter Norvig’s blog post on setting up a simple spell checking algorithm. <a href=\"#link_three\">[3]</a>\n",
    "\n",
    "It uses a Levenshtein Distance algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are more likely the correct results. <a href=\"#link_four\">[4]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python libraries\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create English model\n",
    "spell = SpellChecker(language = 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default Levenshtein distance\n",
    "spell.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beaotipul', 'castli', 'livis'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find those words that may be misspelled\n",
    "misspelled = spell.unknown(['She', 'livis', 'in', 'a', 'beaotipul', 'castli'])\n",
    "misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'castli', 'answer': 'castle', 'options': {'castle'}}\n",
      "{'word': 'livis', 'answer': 'lives', 'options': {'livia', 'divis', 'levis', 'lives', 'livid'}}\n",
      "{'word': 'beaotipul', 'answer': 'beautiful', 'options': {'beautiful'}}\n"
     ]
    }
   ],
   "source": [
    "# Get the one 'most likely' answer and options\n",
    "for word in misspelled:\n",
    "    solution = {'word': word, 'answer': spell.correction(word), 'options': spell.candidates(word)}\n",
    "    print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spanish model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spanish model\n",
    "spell = SpellChecker(language = 'es', distance = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errodes', 'frace'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find those words that may be misspelled\n",
    "misspelled = spell.unknown(['Esta', 'es', 'una', 'frace', 'con', 'errodes'])\n",
    "misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'frace', 'answer': 'grace', 'options': {'france', 'frase', 'frac', 'face', 'trace', 'brace', 'frame', 'race', 'frane', 'grace'}}\n",
      "{'word': 'errodes', 'answer': 'errores', 'options': {'errores'}}\n"
     ]
    }
   ],
   "source": [
    "# Get the one 'most likely' answer and options\n",
    "for word in misspelled:\n",
    "    solution = {'word': word, 'answer': spell.correction(word), 'options': spell.candidates(word)}\n",
    "    print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='link_one' href='https://en.wikipedia.org/wiki/Spell_checker' target='_blank' >[1]</a> Wikipedia - Spell Checker.  \n",
    "<a name='link_two' href='https://norvig.com/spell-correct.html' target='_blank' >[2]</a> Peter Norvig Spell Correct project.  \n",
    "<a name='link_three' href='https://pypi.org/project/pyspellchecker/' target='_blank' >[3]</a> Pypi - PySpellChecker project site.  \n",
    "<a name='link_four' href='https://ansegura7.github.io/NLP/support/pyspellchecker_manual.pdf' target='_blank' >[4]</a> PySpellChecker PDF manual.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><a href=\"https://ansegura7.github.io/NLP/\">« Home</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
