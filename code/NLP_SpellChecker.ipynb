{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Spell Checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Created by Andrés Segura Tinoco**\n",
    "- **Created on June 14, 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Spell checker** (or spell corrector) is an application, program or a feature of a program that checks for misspellings in a text and offers possible solutions (candidate words) <a href=\"#link_one\">[1]</a>.\n",
    "\n",
    "A basic spell checker carries out the following processes:\n",
    "- It scans the text and extracts the words contained in it.\n",
    "- It then compares each word with a known list of correctly spelled words (i.e. a dictionary).\n",
    "- An additional step is a language-dependent algorithm for handling morphology.\n",
    "- The program's user interface will allow users to approve or reject replacements and modify the program's operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spell Checker from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python libraries\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary/vocabulary from a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function to read a plain text file\n",
    "def read_text_file(file_path):\n",
    "    text = \"\"\n",
    "    with io.open(file_path, 'r', encoding = 'ISO-8859-1') as f:\n",
    "        text = f.read()\n",
    "    return text;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235134"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get text sample\n",
    "file_path = \"../data/en/Moby Dick or the Whale - Herman Melville.txt\"\n",
    "plain_text = read_text_file(file_path)\n",
    "len(plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return an array with the clean words of the document: vocabulary\n",
    "def get_vocabulary(plain_text):\n",
    "    vocabulary = []\n",
    "    doc_words = []\n",
    "    \n",
    "    # Cleaing the text\n",
    "    clean_text = plain_text.lower()\n",
    "    clean_text = clean_text.replace('\\n', '.')\n",
    "    clean_text = re.sub('[^a-zA-Z.]', ' ', clean_text)\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    clean_text = re.sub(r'\\.+', \".\", clean_text)\n",
    "\n",
    "    # Tokenize sentences in words\n",
    "    for sentence in clean_text.split('.'):\n",
    "        if sentence.strip() != '':\n",
    "            for word in sentence.split():\n",
    "                if word.strip() != '':\n",
    "                    doc_words.append(word.strip())\n",
    "    \n",
    "    # Get unique words from document\n",
    "    vocabulary = list(set(doc_words))\n",
    "    \n",
    "    return vocabulary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16967"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocabulary = get_vocabulary(plain_text)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lists', 'enemy', 'unbegotten', 'strict', 'begging', 'hindmost', 'derive', 'judith', 'taken', 'uncracked', 'relinquish', 'slapped', 'resist', 'ceremonies', 'childish', 'sixteen', 'explain', 'tips', 'questionable', 'cabalistics', 'inquiry', 'yawed', 'community', 'changing', 'ensuing', 'actions', 'blubber', 'riveted', 'freedom', 'symbolized', 'placards', 'plates', 'lawful', 'horse', 'feathering', 'cable', 'transpired', 'froissart', 'abednego', 'arrive', 'lockers', 'watergate', 'snatching', 'composing', 'predicament', 'miguel', 'equator', 'voyagings', 'banterings', 'thereabouts', 'bellied', 'heavers', 'faded', 'canopy', 'revolvingly', 'reason', 'subdivisible', 'animosity', 'disclosed', 'trace', 'abroad', 'swallowed', 'chinks', 'surrender', 'bag', 'wondering', 'twine', 'echoed', 'noah', 'guilt', 'leaking', 'such', 'fish', 'anglo', 'dearest', 'nimbly', 'scornest', 'quaffed', 'twopence', 'errors', 'colourless', 'lay', 'drawing', 'stratagem', 'owners', 'continue', 'beggar', 'retaken', 'daughters', 'tending', 'hurt', 'glimmering', 'savage', 'other', 'accursed', 'gem', 'nelson', 'tinker', 'investigate', 'sagacious']\n"
     ]
    }
   ],
   "source": [
    "# Show 100 first words of the vocabulary\n",
    "print(vocabulary[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spell Checker model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Peter Norvig’s 21-line spelling corrector using probability theory <a href=\"#link_two\" >[2]</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Spell Checker class\n",
    "class SpellChecker:\n",
    "    \n",
    "    def __init__(self, words):\n",
    "        \"Constructor.\"\n",
    "        self.w_rank = {}\n",
    "        self.letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            self.w_rank[word] = i\n",
    "    \n",
    "    def P(self, word): \n",
    "        \"Probability of 'word'.\"\n",
    "        # use inverse of rank as proxy\n",
    "        # returns 0 if the word isn't in the dictionary\n",
    "        return - self.w_rank.get(word, 0)\n",
    "\n",
    "    def known(self, words): \n",
    "        \"The subset of 'words' that appear in the dictionary of w_rank.\"\n",
    "        return set(w for w in words if w in self.w_rank)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from 'word'.\"\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in self.letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in self.letters]\n",
    "        \n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word): \n",
    "        \"All edits that are two edits away from 'word'.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n",
    "    \n",
    "    def correction(self, word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key = self.P)\n",
    "    \n",
    "    def candidates(self, word): \n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spell Checker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "sp_model = SpellChecker(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'castle'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correction\n",
    "sp_model.correction('castli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'walk', 'weak'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get candidates\n",
    "sp_model.candidates('wlak')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spell Checker using PySpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure Python Spell Checking based on Peter Norvig’s blog post on setting up a simple spell checking algorithm <a href=\"#link_three\">[3]</a>.\n",
    "\n",
    "It uses a Levenshtein Distance algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are more likely the correct results. <a href=\"#link_four\">[4]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python libraries\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create English model\n",
    "spell = SpellChecker(language = 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default Levenshtein distance\n",
    "spell.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beaotipul', 'castli', 'livis'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find those words that may be misspelled\n",
    "misspelled = spell.unknown(['She', 'livis', 'in', 'a', 'beaotipul', 'castli'])\n",
    "misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'castli', 'answer': 'castle', 'options': {'castle'}}\n",
      "{'word': 'livis', 'answer': 'lives', 'options': {'livid', 'levis', 'divis', 'livia', 'lives'}}\n",
      "{'word': 'beaotipul', 'answer': 'beautiful', 'options': {'beautiful'}}\n"
     ]
    }
   ],
   "source": [
    "# Get the one 'most likely' answer and options\n",
    "for word in misspelled:\n",
    "    solution = {'word': word, 'answer': spell.correction(word), 'options': spell.candidates(word)}\n",
    "    print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spanish model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spanish model\n",
    "spell = SpellChecker(language = 'es', distance = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errodes', 'frace'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find those words that may be misspelled\n",
    "misspelled = spell.unknown(['Esta', 'es', 'una', 'frace', 'con', 'errodes'])\n",
    "misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'errodes', 'answer': 'errores', 'options': {'errores'}}\n",
      "{'word': 'frace', 'answer': 'grace', 'options': {'face', 'race', 'frac', 'frane', 'frase', 'france', 'trace', 'brace', 'frame', 'grace'}}\n"
     ]
    }
   ],
   "source": [
    "# Get the one 'most likely' answer and options\n",
    "for word in misspelled:\n",
    "    solution = {'word': word, 'answer': spell.correction(word), 'options': spell.candidates(word)}\n",
    "    print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='link_one'   href='https://en.wikipedia.org/wiki/Spell_checker' target='_blank' >[1]</a> Wikipedia Spell Checker.  \n",
    "<a name='link_two'   href='https://norvig.com/spell-correct.html'       target='_blank' >[2]</a> Peter Norvig Spell Correct.  \n",
    "<a name='link_three' href='https://pypi.org/project/pyspellchecker/'    target='_blank' >[3]</a> PySpellChecker project.  \n",
    "<a name='link_four' href='https://ansegura7.github.io/NLP/support/pyspellchecker_manual.pdf' target='_blank' >[4]</a> PySpellChecker PDF manual.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><a href=\"https://ansegura7.github.io/NLP/\">« Home</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
