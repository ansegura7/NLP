{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1865a41",
   "metadata": {},
   "source": [
    "# NLP - Using Stanza library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4878ed3",
   "metadata": {},
   "source": [
    "- **Created by Andr√©s Segura Tinoco**\n",
    "- **Created on January 21, 2022**\n",
    "- **Updated on January 24, 2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601ed436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stanza\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2cec00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b42b5",
   "metadata": {},
   "source": [
    "## Stanza Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff293713",
   "metadata": {},
   "source": [
    "**Stanza** is a Python NLP toolkit that supports 60+ human languages. It is built with highly accurate neural network components that enable efficient training and evaluation with your own annotated data, and offers pretrained models on 100 treebanks. Additionally, Stanza provides a stable, officially maintained Python interface to Java Stanford CoreNLP Toolkit <a href=\"#link_one\">[1]</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e8997",
   "metadata": {},
   "source": [
    "The following is a set of English sentences from Chapter 1 (\"A SCANDAL IN BOHEMIA\") of the book The Adventures of Sherlock Holmes by Sr. Arthur Conan Doyle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aecf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences\n",
    "en_text = \"\"\"\n",
    "To Sherlock Holmes she is always the woman. \n",
    "I have seldom heard him mention her under any other name. \n",
    "In his eyes she eclipses and predominates the whole of her sex. \n",
    "It was not that he felt any emotion akin to love for Irene Adler.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee286e",
   "metadata": {},
   "source": [
    "### Step 1 - Downloading model\n",
    "Download an English model into the default directory. This command should not always be executed, but only the first time an English model is used or when it needs to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efffea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading English model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading English model...\")\n",
    "#stanza.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2748753",
   "metadata": {},
   "source": [
    "### Step 2 - Creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356abb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 11:04:59 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-01-24 11:04:59 INFO: Use device: cpu\n",
      "2022-01-24 11:04:59 INFO: Loading: tokenize\n",
      "2022-01-24 11:04:59 INFO: Loading: pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building an English pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 11:05:00 INFO: Loading: lemma\n",
      "2022-01-24 11:05:00 INFO: Loading: depparse\n",
      "2022-01-24 11:05:01 INFO: Loading: sentiment\n",
      "2022-01-24 11:05:01 INFO: Loading: ner\n",
      "2022-01-24 11:05:03 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Build an English pipeline, with all processors by default\n",
    "print(\"Building an English pipeline...\")\n",
    "en_nlp = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f0d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stanza.models.common.doc.Document'>\n"
     ]
    }
   ],
   "source": [
    "# Creating English model and processing text\n",
    "en_doc = en_nlp(en_text)\n",
    "print(type(en_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70728e",
   "metadata": {},
   "source": [
    "### Step 3 - Accessing annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3db47b",
   "metadata": {},
   "source": [
    "**NLP task**: Splitting Sentences. Show number of sentences in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddce2ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. sentences: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"No. sentences:\", len(en_doc.sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715bee3",
   "metadata": {},
   "source": [
    "**NLP task**: Part of Speech tagging. Show annotations on the words of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3578f1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence 1]\n",
      "To          \tto          \tADP   \t2\tcase        \n",
      "Sherlock    \tSherlock    \tPROPN \t8\tobl         \n",
      "Holmes      \tHolmes      \tPROPN \t2\tflat        \n",
      "she         \tshe         \tPRON  \t8\tnsubj       \n",
      "is          \tbe          \tAUX   \t8\tcop         \n",
      "always      \talways      \tADV   \t8\tadvmod      \n",
      "the         \tthe         \tDET   \t8\tdet         \n",
      "woman       \twoman       \tNOUN  \t0\troot        \n",
      ".           \t.           \tPUNCT \t8\tpunct       \n",
      "\n",
      "[Sentence 2]\n",
      "I           \tI           \tPRON  \t4\tnsubj       \n",
      "have        \thave        \tAUX   \t4\taux         \n",
      "seldom      \tseldom      \tADV   \t4\tadvmod      \n",
      "heard       \thear        \tVERB  \t0\troot        \n",
      "him         \the          \tPRON  \t4\tobj         \n",
      "mention     \tmention     \tVERB  \t4\txcomp       \n",
      "her         \tshe         \tPRON  \t6\tobj         \n",
      "under       \tunder       \tADP   \t11\tcase        \n",
      "any         \tany         \tDET   \t11\tdet         \n",
      "other       \tother       \tADJ   \t11\tamod        \n",
      "name        \tname        \tNOUN  \t6\tobl         \n",
      ".           \t.           \tPUNCT \t4\tpunct       \n",
      "\n",
      "[Sentence 3]\n",
      "In          \tin          \tADP   \t3\tcase        \n",
      "his         \the          \tPRON  \t3\tnmod:poss   \n",
      "eyes        \teye         \tNOUN  \t5\tobl         \n",
      "she         \tshe         \tPRON  \t5\tnsubj       \n",
      "eclipses    \teclipse     \tVERB  \t0\troot        \n",
      "and         \tand         \tCCONJ \t7\tcc          \n",
      "predominates\tpredominate \tVERB  \t5\tconj        \n",
      "the         \tthe         \tDET   \t9\tdet         \n",
      "whole       \twhole       \tNOUN  \t7\tobj         \n",
      "of          \tof          \tADP   \t12\tcase        \n",
      "her         \tshe         \tPRON  \t12\tnmod:poss   \n",
      "sex         \tsex         \tNOUN  \t9\tnmod        \n",
      ".           \t.           \tPUNCT \t5\tpunct       \n",
      "\n",
      "[Sentence 4]\n",
      "It          \tit          \tPRON  \t2\tnsubj       \n",
      "was         \tbe          \tAUX   \t0\troot        \n",
      "not         \tnot         \tPART  \t2\tadvmod      \n",
      "that        \tthat        \tSCONJ \t6\tmark        \n",
      "he          \the          \tPRON  \t6\tnsubj       \n",
      "felt        \tfeel        \tVERB  \t2\tccomp       \n",
      "any         \tany         \tDET   \t8\tdet         \n",
      "emotion     \temotion     \tNOUN  \t6\tobj         \n",
      "akin        \takin        \tADJ   \t8\tamod        \n",
      "to          \tto          \tPART  \t11\tmark        \n",
      "love        \tlove        \tVERB  \t9\txcomp       \n",
      "for         \tfor         \tADP   \t13\tcase        \n",
      "Irene       \tIrene       \tPROPN \t11\tobl         \n",
      "Adler       \tAdler       \tPROPN \t13\tflat        \n",
      ".           \t.           \tPUNCT \t2\tpunct       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(en_doc.sentences):\n",
    "    print(\"[Sentence {}]\".format(i+1))\n",
    "    for word in sent.words:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
    "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf92dcc",
   "metadata": {},
   "source": [
    "**NLP task**: Named Entity Recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b35fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mention text\tType\tStart-End\n",
      "Sherlock Holmes\tPERSON\t4-19\n",
      "Irene Adler\tPERSON\t223-234\n"
     ]
    }
   ],
   "source": [
    "print(\"Mention text\\tType\\tStart-End\")\n",
    "for ent in en_doc.ents:\n",
    "    print(\"{}\\t{}\\t{}-{}\".format(ent.text, ent.type, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780bd8f",
   "metadata": {},
   "source": [
    "## Stanford CoreNLP interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4dbd4",
   "metadata": {},
   "source": [
    "CoreNLP is your one stop shop for natural language processing in Java! CoreNLP enables users to derive linguistic annotations for text, including token and sentence boundaries, parts of speech, named entities, numeric and time values, dependency and constituency parses, coreference, sentiment, quote attributions, and relations. CoreNLP currently supports 8 languages: Arabic, Chinese, English, French, German, Hungarian, Italian, and Spanish <a href=\"#link_two\">[2]</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84346866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Dev Projects\\\\Libraries\\\\stanford-corenlp-4.3.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_var = \"CORENLP_HOME\"\n",
    "os.environ[env_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7959f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "# Examine the CoreNLP installation folder to make sure the installation is successful\n",
    "!dir {os.environ[env_var]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8545c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import client module\n",
    "import time\n",
    "from stanza.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad9d9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 11:05:04 INFO: Writing properties to tmp file: corenlp_server-aaf3dd7c793a4b29.props\n"
     ]
    }
   ],
   "source": [
    "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 2GB, and port number 9001\n",
    "client = CoreNLPClient(\n",
    "    #properties='spanish',\n",
    "    annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner', 'parse', 'depparse','coref'], \n",
    "    memory='2G', \n",
    "    endpoint='http://localhost:9001',\n",
    "    be_quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249aceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 11:05:04 INFO: Starting server with command: java -Xmx2G -cp C:\\Dev Projects\\Libraries\\stanford-corenlp-4.3.1\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-aaf3dd7c793a4b29.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "# Start the background server and wait for some time\n",
    "client.start()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70771200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.exe                     12944 Console                    3      7,292 K\n",
      "java.exe                     12192 Console                    3  1,024,520 K\n"
     ]
    }
   ],
   "source": [
    "# Print background processes and look for java\n",
    "# You should be able to see a StanfordCoreNLPServer java process running in the background\n",
    "!tasklist | findstr java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19aea193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'CoreNLP_pb2.Document'>\n"
     ]
    }
   ],
   "source": [
    "# Annotate English text\n",
    "document = client.annotate(en_text)\n",
    "print(type(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "661cf6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word        \tLemma       \tPOS   \tNER\n",
      "[Sentence 1]\n",
      "To          \tto          \tTO    \tO\n",
      "Sherlock    \tSherlock    \tNNP   \tPERSON\n",
      "Holmes      \tHolmes      \tNNP   \tPERSON\n",
      "she         \tshe         \tPRP   \tO\n",
      "is          \tbe          \tVBZ   \tO\n",
      "always      \talways      \tRB    \tO\n",
      "the         \tthe         \tDT    \tO\n",
      "woman       \twoman       \tNN    \tO\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "[Sentence 2]\n",
      "I           \tI           \tPRP   \tO\n",
      "have        \thave        \tVBP   \tO\n",
      "seldom      \tseldom      \tRB    \tO\n",
      "heard       \thear        \tVBN   \tO\n",
      "him         \the          \tPRP   \tO\n",
      "mention     \tmention     \tVB    \tO\n",
      "her         \tshe         \tPRP$  \tO\n",
      "under       \tunder       \tIN    \tO\n",
      "any         \tany         \tDT    \tO\n",
      "other       \tother       \tJJ    \tO\n",
      "name        \tname        \tNN    \tO\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "[Sentence 3]\n",
      "In          \tin          \tIN    \tO\n",
      "his         \the          \tPRP$  \tO\n",
      "eyes        \teye         \tNNS   \tO\n",
      "she         \tshe         \tPRP   \tO\n",
      "eclipses    \teclipse     \tVBZ   \tO\n",
      "and         \tand         \tCC    \tO\n",
      "predominates\tpredominate \tVBZ   \tO\n",
      "the         \tthe         \tDT    \tO\n",
      "whole       \twhole       \tNN    \tO\n",
      "of          \tof          \tIN    \tO\n",
      "her         \tshe         \tPRP$  \tO\n",
      "sex         \tsex         \tNN    \tO\n",
      ".           \t.           \t.     \tO\n",
      "\n",
      "[Sentence 4]\n",
      "It          \tit          \tPRP   \tO\n",
      "was         \tbe          \tVBD   \tO\n",
      "not         \tnot         \tRB    \tO\n",
      "that        \tthat        \tIN    \tO\n",
      "he          \the          \tPRP   \tO\n",
      "felt        \tfeel        \tVBD   \tO\n",
      "any         \tany         \tDT    \tO\n",
      "emotion     \temotion     \tNN    \tO\n",
      "akin        \takin        \tJJ    \tO\n",
      "to          \tto          \tTO    \tO\n",
      "love        \tlove        \tVB    \tO\n",
      "for         \tfor         \tIN    \tO\n",
      "Irene       \tIrene       \tNNP   \tPERSON\n",
      "Adler       \tAdler       \tNNP   \tPERSON\n",
      ".           \t.           \t.     \tO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all tokens in all sentences, and print out the word, lemma, pos and ner tags\n",
    "print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(\"Word\", \"Lemma\", \"POS\", \"NER\"))\n",
    "\n",
    "for i, sent in enumerate(document.sentence):\n",
    "    print(\"[Sentence {}]\".format(i+1))\n",
    "    for t in sent.token:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(t.word, t.lemma, t.pos, t.ner))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a365410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mention                       \tType\n",
      "Sherlock Holmes               \tPERSON\n",
      "she                           \tPERSON\n",
      "him                           \tPERSON\n",
      "her                           \tPERSON\n",
      "his                           \tPERSON\n",
      "she                           \tPERSON\n",
      "her                           \tPERSON\n",
      "Irene Adler                   \tPERSON\n",
      "he                            \tPERSON\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all detected entity mentions\n",
    "print(\"{:30s}\\t{}\".format(\"Mention\", \"Type\"))\n",
    "\n",
    "for sent in document.sentence:\n",
    "    for m in sent.mentions:\n",
    "        print(\"{:30s}\\t{}\".format(m.entityMentionText, m.entityType))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f98dcd",
   "metadata": {},
   "source": [
    "**NLP task**: Constituency Parse Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "274b0d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child {\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        value: \"To\"\n",
      "      }\n",
      "      value: \"TO\"\n",
      "      score: -4.007333278656006\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"Sherlock\"\n",
      "        }\n",
      "        value: \"NNP\"\n",
      "        score: -11.400341033935547\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          value: \"Holmes\"\n",
      "        }\n",
      "        value: \"NNP\"\n",
      "        score: -9.204214096069336\n",
      "      }\n",
      "      value: \"NP\"\n",
      "      score: -23.002450942993164\n",
      "    }\n",
      "    value: \"WHPP\"\n",
      "    score: -34.39811325073242\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"she\"\n",
      "        }\n",
      "        value: \"PRP\"\n",
      "        score: -3.9035301208496094\n",
      "      }\n",
      "      value: \"NP\"\n",
      "      score: -4.765097141265869\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"is\"\n",
      "        }\n",
      "        value: \"VBZ\"\n",
      "        score: -0.14797931909561157\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          child {\n",
      "            value: \"always\"\n",
      "          }\n",
      "          value: \"RB\"\n",
      "          score: -4.51917028427124\n",
      "        }\n",
      "        value: \"ADVP\"\n",
      "        score: -4.762180328369141\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          child {\n",
      "            value: \"the\"\n",
      "          }\n",
      "          value: \"DT\"\n",
      "          score: -0.5893322825431824\n",
      "        }\n",
      "        child {\n",
      "          child {\n",
      "            value: \"woman\"\n",
      "          }\n",
      "          value: \"NN\"\n",
      "          score: -6.736452579498291\n",
      "        }\n",
      "        value: \"NP\"\n",
      "        score: -9.268684387207031\n",
      "      }\n",
      "      value: \"VP\"\n",
      "      score: -21.771156311035156\n",
      "    }\n",
      "    value: \"S\"\n",
      "    score: -26.872772216796875\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      value: \".\"\n",
      "    }\n",
      "    value: \".\"\n",
      "    score: -0.43762221932411194\n",
      "  }\n",
      "  value: \"SBAR\"\n",
      "  score: -66.49877166748047\n",
      "}\n",
      "value: \"ROOT\"\n",
      "score: -72.68036651611328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = document.sentence[0]\n",
    "constituency_parse = sentence.parseTree\n",
    "print(constituency_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "768830a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.exe                     12192 Console                    3  2,294,324 K\n"
     ]
    }
   ],
   "source": [
    "# Shut down the background CoreNLP server\n",
    "client.stop()\n",
    "time.sleep(10)\n",
    "!tasklist | findstr java"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9b03b",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c871f",
   "metadata": {},
   "source": [
    "<a name='link_one' href='https://stanfordnlp.github.io/stanza/' target='_blank' >[1]</a> Stanza home page.  \n",
    "<a name='link_two' href='https://stanfordnlp.github.io/CoreNLP/' target='_blank' >[2]</a> Stanford CoreNLP home page.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc896790",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><a href=\"https://ansegura7.github.io/NLP/\">¬´ Home</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
