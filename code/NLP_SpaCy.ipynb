{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Using spaCy library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Created by Andrés Segura Tinoco**\n",
    "- **Created on June 04, 2019**\n",
    "- **Updated on October 29, 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Natural language processing (NLP):** is a discipline where computer science, artificial intelligence and cognitive logic are intercepted, with the objective that machines can read and understand our language for decision making <a href=\"#link_one\">[1]</a>.\n",
    "\n",
    "**spaCy:** features fast statistical NER as well as an open-source named-entity visualizer <a href=\"#link_two\">[2]</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with a document in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python libraries\n",
    "import io\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLP libraries from spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify installed spacy version\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Read natural text from a book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function to read a plain text file\n",
    "def read_text_file(file_path, encoding='ISO-8859-1'):\n",
    "    text = \"\"\n",
    "    with open(file_path, 'r', encoding=encoding) as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text sample\n",
    "file_path = \"../data/es/El Grillo del Hogar - Charles Dickens.txt\"\n",
    "book_text = read_text_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El grillo del hogar\\n(The Cricket of the Heard)\\nde\\n\\nCharles Dickens\\nEste libro electrónico es cortesía de\\n\\nhttp://www.dominiopublico.es\\nPrimer grito\\nCapítulo I\\nCapítulo II\\nCapítulo III\\nCapítulo IV\\nCapítulo V\\nCapítulo VI\\nSegundo grito\\nCapítulo I\\nCapítulo II\\nCapítulo III\\nCapítulo IV\\nCapítulo V\\nCapítulo VI\\nTercer grito\\nCapítulo I\\nCapítulo II\\nCapítulo III\\nCapítulo IV\\nCapítulo V\\nCapítulo VI\\n\\nPrimer grito\\n- I -\\nEmpezó el puchero. No necesito que me contéis lo que la señora Peerybingle dijera; yo me entiendo. Dejad que la señora Peerybingle se pase hasta la consumación de los siglos asegurando la imposibilidad de decidir cuál empezó: yo digo que fue el puchero. Tengo motivos para saberlo. El puchero empezó cinco minutos antes que el grillo, según el relojito holandés de cuadrante barnizado situado en el rincón.\\n¡Como si el reloj no hubiese cesado de tocar! ¡Como si el segadorcido de movimientos convulsivos y bruscos que lo remata, paseando la hoz de derecha a izquierda y luego de izquierda a d'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 1000 raw characters of document\n",
    "book_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create a NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NLP model for spanish language\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "doc_es = nlp(book_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Vocabulary:** unique words of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vocabulary\n",
    "vocabulary_es = set(str(token).lower() for token in doc_es if not token.is_stop and token.is_alpha)\n",
    "len(vocabulary_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rastrojos', 'esperad', 'dicha', 'reconozco', 'ajeno', 'particularmente', 'ocasiones', 'volveré', 'reproducir', 'peatones', 'guiarme', 'imagen', 'pendía', 'delgado', 'bastantes', 'llenando', 'sinónimo', 'caballos', 'atravesaban', 'ocultó', 'cuero', 'extemporáneo', 'alta', 'infinidad', 'inconcebible', 'consoladoras', 'siglo', 'simpatía', 'consolarse', 'hogar', 'pensionado', 'punta', 'levantarse', 'vigoroso', 'agradable', 'salió', 'perfecta', 'carcajada', 'cabecera', 'apasionado', 'estrambótica', 'demuestra', 'encontrarse', 'presente', 'examinarle', 'helaría', 'abramos', 'empeño', 'acudió', 'iniciales', 'enmohecía', 'cancioncilla', 'permitieseis', 'diversión', 'envía', 'cogerle', 'consejos', 'trabajaban', 'acá', 'incidentes', 'enlazadas', 'radiante', 'objetar', 'parado', 'preparativos', 'parándose', 'seguida', 'perfeccionamiento', 'bendito', 'vasija', 'preciso', 'sospecha', 'hayáis', 'reconocerlas', 'público', 'comparación', 'calmarla', 'quince', 'siquiera', 'exceda', 'expuesta', 'acaso', 'directa', 'a', 'tratado', 'cadena', 'intencionado', 'dirección', 'retiró', 'alejé', 'interrumpió', 'herida', 'caballero', 'descubrir', 'atareado', 'desdichada', 'areópago', 'regordetillas', 'entornado', 'rechazado']\n"
     ]
    }
   ],
   "source": [
    "# Show 100 random words of the vocabulary\n",
    "print(random.sample(vocabulary_es, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Stopwords:** refers to the most common words in a language, which do not significantly affect the meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique stop-words\n",
    "stop_words_es = set(str(token).lower() for token in doc_es if token.is_stop)\n",
    "len(stop_words_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mi', 'su', 'ella', 'nunca', 'mayor', 'puedo', 'ésa', 'manera', 'quiere', 'pronto', 'fui', 'nosotras', 'tercera', 'como', 'sois', 'podrían', 'trata', 'ver', 'estar', 'cuándo', 'creo', 'uno', 'varias', 'así', 'primero', 'vuestra', 'algunas', 'excepto', 'días', 'entre', 'los', 'aquella', 'cuál', 'respecto', 'cosas', 'hace', 'tal', 'sé', 'de', 'usted', 'algo', 'final', 'eso', 'está', 'estaban', 'suyo', 'nos', 'algunos', 'trabajo', 'dijeron', 'haya', 'demás', 'tenía', 'tuyos', 'anterior', 'ningún', 'seis', 'conmigo', 'yo', 'según', 'al', 'alguna', 'quién', 'unos', 'pasado', 'tan', 'hicieron', 'mí', 'antes', 'señaló', 'aún', 'estoy', 'se', 'nadie', 'aquí', 'pudo', 'vuestras', 'dan', 'verdad', 'tiempo', 'quienes', 'breve', 'hacer', 'mas', 'manifestó', 'grandes', 'sola', 'tenido', 'en', 'tener', 'sino', 'estuvo', 'dicen', 'temprano', 'debe', 'cierto', 'están', 'ese', 'hemos', 'será', 'nuestras', 'dio', 'ésta', 'vuestro', 'cinco', 'toda', 'mismo', 'todos', 'quedó', 'tarde', 'cuando', 'he', 'realizar', 'encuentra', 'somos', 'que', 'dar', 'nuestra', 'suyas', 'sea', 'consigo', 'dice', 'adelante', 'te', 'pero', 'indicó', 'cuenta', 'tengo', 'todas', 'mediante', 'añadió', 'ambos', 'uso', 'ni', 'propias', 'encima', 'mejor', 'es', 'vais', 'diferente', 'verdadero', 'estamos', 'solo', 'buena', 'estas', 'esta', 'ellos', 'siendo', 'voy', 'saber', 'poner', 'gran', 'demasiado', 'llevar', 'hizo', 'siempre', 'vuestros', 'ello', 'fin', 'casi', 'por', 'último', 'debajo', 'pocas', 'tus', 'tampoco', 'cuántos', 'han', 'sabemos', 'éste', 'tu', 'ser', 'lo', 'deben', 'veces', 'incluso', 'un', 'aunque', 'nuevos', 'nuevas', 'para', 'momento', 'claro', 'ahora', 'vaya', 'hacerlo', 'había', 'mucha', 'podemos', 'éstos', 'propio', 'apenas', 'dicho', 'peor', 'le', 'dos', 'largo', 'nueva', 'sus', 'nada', 'eran', 'delante', 'va', 'otras', 'una', 'otros', 'luego', 'ningunos', 'haciendo', 'os', 'buenas', 'existe', 'explicó', 'qué', 'día', 'cual', 'pocos', 'desde', 'aquél', 'ha', 'son', 'poca', 'todo', 'mientras', 'dado', 'habrá', 'otra', 'ya', 'les', 'quiénes', 'mucho', 'cuanto', 'mismas', 'van', 'cuales', 'cuánto', 'cómo', 'buen', 'pasada', 'me', 'mal', 'donde', 'puede', 'soy', 'segundo', 'partir', 'verdadera', 'cuatro', 'medio', 'sin', 'tiene', 'menudo', 'ahí', 'detrás', 'estaba', 'ante', 'porque', 'cada', 'esa', 'algún', 'muchas', 'lejos', 'mismos', 'buenos', 'hubo', 'después', 'usar', 'parte', 'esos', 'arriba', 'bueno', 'lugar', 'misma', 'tuvo', 'pueda', 'última', 'era', 'propios', 'fuera', 'quien', 'igual', 'estará', 'sería', 'nuevo', 'cualquier', 'habla', 'aun', 'dijo', 'ninguna', 'con', 'menos', 'principalmente', 'suya', 'él', 'tenemos', 'ciertas', 'hacemos', 'existen', 'estos', 'da', 'ti', 'pesar', 'también', 'tanto', 'sido', 'hecho', 'tres', 'segunda', 'debido', 'allí', 'bastante', 'hacia', 'general', 'ejemplo', 'esas', 'pueden', 'próximos', 'más', 'nuestro', 'poco', 'ellas', 'ayer', 'trabajan', 'vez', 'podrá', 'cuantos', 'ciertos', 'expresó', 'sobre', 'valor', 'mío', 'alguno', 'siguiente', 'la', 'realizado', 'tienen', 'todavía', 'alrededor', 'poder', 'vosotros', 'propia', 'mis', 'mía', 'no', 'lado', 'primer', 'través', 'próximo', 'saben', 'decir', 'muy', 'tendrá', 'conocer', 'modo', 'aquel', 'solas', 'el', 'sigue', 'aquélla', 'cierta', 'tenga', 'últimas', 'cerca', 'podría', 'esto', 'realizó', 'muchos', 'habían', 'cuantas', 'vamos', 'contra', 'horas', 'sean', 'tras', 'sabe', 'acuerdo', 'fue', 'llegó', 'solamente', 'dentro', 'junto', 'hoy', 'ir', 'además', 'solos', 'dieron', 'entonces', 'aquellos', 'dónde', 'bajo', 'hay', 'estado', 'trabajar', 'pues', 'raras', 'las', 'posible', 'quizá', 'bien', 'hasta', 'si', 'primera', 'dejó', 'haber', 'parece', 'fueron', 'ustedes', 'sí', 'míos', 'sólo', 'este', 'nosotros', 'unas', 'otro', 'del', 'durante'}\n"
     ]
    }
   ],
   "source": [
    "# Show unique stop-words\n",
    "print(stop_words_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Entity:** can be any word or series of words that consistently refers to the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Entity: The Cricket of the Heard , Label: MISC\n",
      "2 - Entity: Charles Dickens , Label: PER\n",
      "3 - Entity: Este libro electrónico , Label: MISC\n",
      "4 - Entity: Primer grito , Label: MISC\n",
      "5 - Entity: Capítulo I , Label: PER\n",
      "6 - Entity: Capítulo II , Label: PER\n",
      "7 - Entity: Capítulo III , Label: PER\n",
      "8 - Entity: Capítulo IV , Label: PER\n",
      "9 - Entity: Capítulo V , Label: PER\n",
      "10 - Entity: Capítulo VI , Label: PER\n",
      "11 - Entity: Segundo grito , Label: MISC\n",
      "12 - Entity: Capítulo I , Label: PER\n",
      "13 - Entity: Capítulo II , Label: PER\n",
      "14 - Entity: Capítulo III , Label: PER\n",
      "15 - Entity: Capítulo IV , Label: PER\n",
      "16 - Entity: Capítulo V , Label: PER\n",
      "17 - Entity: Capítulo VI , Label: PER\n",
      "18 - Entity: Tercer , Label: MISC\n",
      "19 - Entity: Capítulo I , Label: PER\n",
      "20 - Entity: Capítulo II , Label: PER\n",
      "21 - Entity: Capítulo III , Label: PER\n",
      "22 - Entity: Capítulo IV , Label: PER\n",
      "23 - Entity: Capítulo V , Label: PER\n",
      "24 - Entity: Capítulo VI , Label: PER\n",
      "25 - Entity: Primer , Label: MISC\n",
      "27 - Entity: Empezó , Label: PER\n",
      "28 - Entity: No necesito que me contéis , Label: MISC\n",
      "29 - Entity: Peerybingle , Label: ORG\n",
      "30 - Entity: Dejad , Label: PER\n",
      "31 - Entity: Peerybingle , Label: ORG\n",
      "32 - Entity: Tengo , Label: PER\n",
      "33 - Entity: El puchero empezó , Label: MISC\n",
      "34 - Entity: A decir verdad , Label: MISC\n",
      "35 - Entity: Por nada del mundo opondría mi opinión personal , Label: MISC\n",
      "36 - Entity: Peerybingle , Label: ORG\n",
      "37 - Entity: Dejarme contar el caso tal como ocurrió , Label: MISC\n",
      "38 - Entity: ¿cómo queréis que empiece por el principio , Label: MISC\n",
      "39 - Entity: Parecía , Label: PER\n",
      "40 - Entity: Una lucha musical , Label: MISC\n",
      "41 - Entity: Vais , Label: PER\n",
      "42 - Entity: La señora Peerybingle , Label: MISC\n",
      "43 - Entity: Euclides , Label: PER\n",
      "44 - Entity: La señora Peerybingle , Label: MISC\n",
      "45 - Entity: De vuelta ya , Label: MISC\n",
      "46 - Entity: Peerybingle muy pequeña- , Label: MISC\n",
      "47 - Entity: Peerybingle , Label: ORG\n",
      "48 - Entity: Además , Label: PER\n",
      "49 - Entity: No quería dejarse acomodar sobre la barra superior de la rejilla , Label: MISC\n",
      "50 - Entity: Peerybingle , Label: ORG\n"
     ]
    }
   ],
   "source": [
    "# Returns a text with data quality\n",
    "def text_quality(text):\n",
    "    new_text = text.replace('\\n', '')\n",
    "    return new_text.strip('\\r\\n')\n",
    "\n",
    "# Print out named first 50 entities\n",
    "for ix in range(50):\n",
    "    ent = doc_es.ents[ix]\n",
    "    ent_text = text_quality(ent.text)\n",
    "    \n",
    "    if len(ent_text) > 3:\n",
    "        print((ix + 1), '- Entity:', ent_text, ', Label:', ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Working with POS, NER and sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- POS:** the parts of speech explain how a word is used in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'AUX',\n",
       " 'CCONJ',\n",
       " 'DET',\n",
       " 'INTJ',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PART',\n",
       " 'PRON',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'SCONJ',\n",
       " 'SPACE',\n",
       " 'SYM',\n",
       " 'VERB'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of speech (POS) used in this document\n",
    "set(token.pos_ for token in doc_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Sentences:** a set of words that is complete in itself and typically containing a subject and predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1699"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many sentences are in this text?\n",
    "sentences = [s for s in doc_es.sents]\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Capítulo IV,\n",
       " ,\n",
       " Capítulo V\n",
       " Capítulo VI,\n",
       " Segundo grito\n",
       " Capítulo I\n",
       " Capítulo II\n",
       " Capítulo III\n",
       " Capítulo IV,\n",
       " Capítulo V\n",
       " Capítulo VI,\n",
       " Tercer grito\n",
       " Capítulo I\n",
       " Capítulo II\n",
       " Capítulo III\n",
       " Capítulo IV,\n",
       " Capítulo V\n",
       " Capítulo VI\n",
       " \n",
       " Primer,\n",
       " grito\n",
       " - I -\n",
       " Empezó el puchero.,\n",
       " No necesito que me contéis lo que la señora Peerybingle dijera; yo me entiendo.,\n",
       " Dejad que la señora Peerybingle se pase hasta la consumación de los siglos asegurando la imposibilidad de decidir cuál empezó: yo digo que fue el puchero.]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 10 sentences\n",
    "sentences[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sentences in which the 'grillo' appears\n",
    "pattern = 'grillo'\n",
    "cricket_sent = [sent for sent in doc_es.sents if pattern in sent.text]\n",
    "len(cricket_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- El puchero empezó cinco minutos antes que el grillo, según el relojito holandés de cuadrante barnizado situado en el rincón.\n",
      "- \n",
      "¡Como si el reloj no hubiese cesado de tocar! ¡Como si el segadorcido de movimientos convulsivos y bruscos que lo remata, paseando la hoz de derecha a izquierda y luego de izquierda a derecha ante la fachada de su palacio morisco, no hubiese segado medio acre de césped imaginario antes que el grillo hubiese hecho notar su presencia!\n",
      "A decir verdad, no fui nunca terco, como todo el mundo sabe.\n",
      "- Pero se trata de una cuestión de hecho, y el hecho es que el puchero empezó por lo menos cinco minutos antes que el grillo hubiese dado señal de vida.\n",
      "- Es lo que hubiera hecho desde la primera frase a no considerar que si cuento una historia debo empezar por el principio, y ¿cómo queréis que empiece por el principio si no empiezo por la vasija?\n",
      "Parecía que la vasija y el grillo luchaban.\n",
      "- Aquí, precisamente en este punto, fue cuando el grillo entró en escena con un crrri, crrri, crrri, de magnífica potencia a coro con el puchero; pero con una voz tan asombradamente desproporcionada a su estatura -¡su estatura!, era casi invisible-, sobre todo comparándole con el puchero, que si por desgracia hubiese reventado como un cañón excesivamente cargado, cayendo, víctima de su celo, su cuerpecito roto en mil fragmentos, no hubiera parecido sino la consecuencia natural y perseguida con su trabajo afanoso.\n",
      "- Perseveró con ardor constante; pero el grillo se erigió en concertino y se mantuvo en su supremacía.\n",
      "- No obstante, marchaban muy bien unidos el grillo y el puchero.\n",
      "- Cuando volvió a sentarse en su sitio, el grillo y el puchero se esmeraban todavía en el canto con cierta rivalidad furiosa, siendo indudablemente el lado flaco del puchero la presunción de vencer constantemente.\n",
      "- El grillo logra una milla de delantera.\n",
      "- ¡Crrri, crrri, crrri!..., el grillo dobla la esquina.\n"
     ]
    }
   ],
   "source": [
    "# Show the first 10 sentences in which the 'grillo' appears\n",
    "for sent in cricket_sent[1:11]:\n",
    "    print('-', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- NER:** Named Entity Recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the most common entities and their quantity\n",
    "def find_entities(doc, ent_type, n):\n",
    "    entities = Counter()\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == ent_type:\n",
    "            ent_name = text_quality(ent.lemma_)\n",
    "            entities[ent_name] += 1\n",
    "    \n",
    "    return entities.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 153),\n",
       " ('Tackleton', 68),\n",
       " ('Caleb', 56),\n",
       " ('Berta', 43),\n",
       " ('May', 38),\n",
       " ('John-', 16),\n",
       " ('John Peerybingle', 15),\n",
       " ('Tilly', 14),\n",
       " ('¿', 12),\n",
       " ('después', 10),\n",
       " ('Tilly Slowboy', 8),\n",
       " ('Dot', 7),\n",
       " ('Eduardo', 7),\n",
       " ('May Fielding', 6),\n",
       " ('Sol', 5),\n",
       " ('aquí', 5),\n",
       " ('Peerybingle', 5),\n",
       " ('ir', 5),\n",
       " ('además', 4),\n",
       " ('¡ Crrri', 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show entities of type PERSON\n",
    "find_entities(doc_es, 'PER', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns persons adjectives\n",
    "def get_person_adj(doc, person):\n",
    "    adjectives = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.lemma_ == person:\n",
    "            for token in ent.subtree:\n",
    "                if token.pos_ == 'ADJ': # Adjective\n",
    "                    adjectives.append(token.lemma_)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.lemma_ == person:\n",
    "            if ent.root.dep_ == 'nsubj': # Nominal subject\n",
    "                for child in ent.root.head.children:\n",
    "                    if child.dep_ == 'acomp': # Adjectival complement\n",
    "                        adjectives.append(child.lemma_)\n",
    "    \n",
    "    return set(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distraído', 'venturoso', 'cabizbajo', 'diligente', 'eficazmente', 'santo', 'turbada-', 'pensativo', 'amado', 'extrañado'}\n"
     ]
    }
   ],
   "source": [
    "# Show the adjectives used for John (most common entity)\n",
    "curr_person = 'John'\n",
    "print(get_person_adj(doc_es, curr_person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the people who use a certain verb\n",
    "def verb_persons(doc, verb, n):\n",
    "    verb_count = Counter()\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PER' and ent.root.head.lemma_ == verb:\n",
    "            verb_count[ent.text] += 1\n",
    "    \n",
    "    return verb_count.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 3),\n",
       " ('Pronto', 1),\n",
       " ('Tiempo', 1),\n",
       " ('Hacía', 1),\n",
       " ('Tackleton', 1),\n",
       " ('Hizo', 1),\n",
       " ('Tilly', 1),\n",
       " ('¡Cuánto', 1),\n",
       " ('May', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the people who use a certain verb\n",
    "curr_verb = 'hacer'\n",
    "verb_persons(doc_es, curr_verb, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ADJ type labels\n",
    "adj_tokens = set(str(token.orth_).lower() for token in doc_es if token.pos_ == 'ADJ')\n",
    "len(adj_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confiada', 'viejo', 'abierta', 'turbada-', 'privado', 'levantadas', 'patético', 'única', 'sorprendido', 'supremo', 'aires', 'sordo', 'echado', 'codicioso', 'vivísima', 'vivarachos', 'ensimismado', 'justísimo', 'alegro', 'convulsiva', 'ingenua', 'cruzadas', 'gentil', 'riguroso', 'verde', 'ocupadísima', 'holandés', 'bolso', 'tetera', 'insensible', 'franca', 'rígido', 'creciente', 'guantes', 'doméstico', 'insaciable', 'sano', 'vivo', 'verdaderos', 'indiferentes', 'útil', 'musical', 'próximos', 'generoso', 'egoísta', 'tiernas', 'hundida', 'arrebatadora', 'consabida', 'crema']\n"
     ]
    }
   ],
   "source": [
    "# Show 50 random ADJ type labels\n",
    "print(random.sample(adj_tokens, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get PROPN type labels\n",
    "propn_tokens = set(str(token.orth_).lower() for token in doc_es if token.pos_ == 'PROPN')\n",
    "len(adj_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cruel', 'madre', 'vivía', 'tackleton', 'soltarme', 'vi', '-era', '-¡el', 'padre', 'experiencia-', 'leed', '-o', '-murmuró', 'juro', 'cuán', 'verdad', 'error', '-¡berta', '-siguió', 'n.', 'vedle', 'tac', 'sepa', 'cámara', 'peerybingle', 'royal-george', 'mía', 'pobre', 'era-', 'shem', 'habríais', '-¡oh', 'crrri', 'sansón', 'regocijado-', '-(n.', 'peerybingle-', 'tic', 'fuerzas-', 'invariablemente', 'indudablemente', '-john', 'eduardo', 'dímelo', 'cuánto', 'hija', 'mecía', 'apiadaos', 'berta-', 'gruff']\n"
     ]
    }
   ],
   "source": [
    "# Show 50 random PROPN type labels\n",
    "print(random.sample(propn_tokens, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='link_one' href='https://en.wikipedia.org/wiki/Natural_language_processing' target='_blank' >[1]</a> Wikipedia - Natural language processing.  \n",
    "<a name='link_two' href='https://spacy.io/' target='_blank' >[2]</a> spaCy website.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p><a href=\"https://ansegura7.github.io/NLP/\">« Home</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
